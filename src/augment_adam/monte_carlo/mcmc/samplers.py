"""
Samplers for Markov Chain Monte Carlo.

This module provides samplers for Markov Chain Monte Carlo, including
Metropolis-Hastings, Gibbs, and Hamiltonian Monte Carlo.
"""

import math
import random
import numpy as np
from typing import Dict, List, Any, Optional, Union, Tuple, Callable, TypeVar, Generic

from augment_adam.utils.tagging import tag, TagCategory
from augment_adam.monte_carlo.mcmc.base import MarkovChainMonteCarlo, MCMCSample, ProposalDistribution


T = TypeVar('T')  # Type of sample


@tag("monte_carlo.mcmc")
class MetropolisHastings(MarkovChainMonteCarlo[T]):
    """
    Metropolis-Hastings algorithm for Markov Chain Monte Carlo.
    
    This class implements the Metropolis-Hastings algorithm, which is a general
    MCMC method for sampling from a probability distribution.
    
    Attributes:
        name: The name of the MCMC method.
        metadata: Additional metadata for the MCMC method.
        samples: The samples generated by the MCMC method.
        target_log_prob_fn: The target log probability function.
        proposal_distribution: The proposal distribution.
    
    TODO(Issue #9): Add support for multiple proposal distributions
    TODO(Issue #9): Implement MCMC diagnostics
    """
    
    def __init__(
        self,
        target_log_prob_fn: Callable[[T], float],
        proposal_distribution: ProposalDistribution[T],
        name: str = "metropolis_hastings"
    ) -> None:
        """
        Initialize the Metropolis-Hastings algorithm.
        
        Args:
            target_log_prob_fn: The target log probability function.
            proposal_distribution: The proposal distribution.
            name: The name of the MCMC method.
        """
        super().__init__(target_log_prob_fn, name)
        
        self.proposal_distribution = proposal_distribution
    
    def sample(
        self,
        initial_state: T,
        num_samples: int,
        num_burnin: int = 0,
        thin: int = 1
    ) -> List[MCMCSample[T]]:
        """
        Generate samples using the Metropolis-Hastings algorithm.
        
        Args:
            initial_state: The initial state of the Markov chain.
            num_samples: The number of samples to generate.
            num_burnin: The number of burn-in samples to discard.
            thin: The thinning factor.
            
        Returns:
            The generated samples.
        """
        # Initialize the Markov chain
        current_state = initial_state
        current_log_prob = self.target_log_prob_fn(current_state)
        
        # Initialize samples
        samples = []
        
        # Run the Markov chain
        for i in range(num_burnin + num_samples * thin):
            # Propose a new state
            proposed_state = self.proposal_distribution.propose(current_state)
            proposed_log_prob = self.target_log_prob_fn(proposed_state)
            
            # Compute the acceptance probability
            log_accept_prob = proposed_log_prob - current_log_prob
            log_accept_prob += self.proposal_distribution.log_probability(current_state, proposed_state)
            log_accept_prob -= self.proposal_distribution.log_probability(proposed_state, current_state)
            
            # Accept or reject the proposal
            accepted = False
            if math.log(random.random()) < log_accept_prob:
                current_state = proposed_state
                current_log_prob = proposed_log_prob
                accepted = True
            
            # Store the sample
            if i >= num_burnin and (i - num_burnin) % thin == 0:
                sample = MCMCSample(current_state, current_log_prob)
                sample.set_metadata("accepted", accepted)
                samples.append(sample)
        
        # Store the samples
        self.samples = samples
        
        return samples


@tag("monte_carlo.mcmc")
class GibbsSampler(MarkovChainMonteCarlo[List[Any]]):
    """
    Gibbs sampler for Markov Chain Monte Carlo.
    
    This class implements the Gibbs sampler, which is an MCMC method for
    sampling from a multivariate probability distribution.
    
    Attributes:
        name: The name of the MCMC method.
        metadata: Additional metadata for the MCMC method.
        samples: The samples generated by the MCMC method.
        target_log_prob_fn: The target log probability function.
        conditional_samplers: The conditional samplers for each dimension.
    
    TODO(Issue #9): Add support for block Gibbs sampling
    TODO(Issue #9): Implement MCMC diagnostics
    """
    
    def __init__(
        self,
        target_log_prob_fn: Callable[[List[Any]], float],
        conditional_samplers: List[Callable[[List[Any], int], Any]],
        name: str = "gibbs_sampler"
    ) -> None:
        """
        Initialize the Gibbs sampler.
        
        Args:
            target_log_prob_fn: The target log probability function.
            conditional_samplers: The conditional samplers for each dimension.
            name: The name of the MCMC method.
        """
        super().__init__(target_log_prob_fn, name)
        
        self.conditional_samplers = conditional_samplers
    
    def sample(
        self,
        initial_state: List[Any],
        num_samples: int,
        num_burnin: int = 0,
        thin: int = 1
    ) -> List[MCMCSample[List[Any]]]:
        """
        Generate samples using the Gibbs sampler.
        
        Args:
            initial_state: The initial state of the Markov chain.
            num_samples: The number of samples to generate.
            num_burnin: The number of burn-in samples to discard.
            thin: The thinning factor.
            
        Returns:
            The generated samples.
        """
        # Initialize the Markov chain
        current_state = initial_state.copy()
        current_log_prob = self.target_log_prob_fn(current_state)
        
        # Initialize samples
        samples = []
        
        # Run the Markov chain
        for i in range(num_burnin + num_samples * thin):
            # Update each dimension
            for j in range(len(current_state)):
                # Sample from the conditional distribution
                current_state[j] = self.conditional_samplers[j](current_state, j)
            
            # Compute the log probability
            current_log_prob = self.target_log_prob_fn(current_state)
            
            # Store the sample
            if i >= num_burnin and (i - num_burnin) % thin == 0:
                sample = MCMCSample(current_state.copy(), current_log_prob)
                samples.append(sample)
        
        # Store the samples
        self.samples = samples
        
        return samples


@tag("monte_carlo.mcmc")
class HamiltonianMC(MarkovChainMonteCarlo[np.ndarray]):
    """
    Hamiltonian Monte Carlo for Markov Chain Monte Carlo.
    
    This class implements Hamiltonian Monte Carlo, which is an MCMC method
    that uses Hamiltonian dynamics to propose new samples.
    
    Attributes:
        name: The name of the MCMC method.
        metadata: Additional metadata for the MCMC method.
        samples: The samples generated by the MCMC method.
        target_log_prob_fn: The target log probability function.
        target_log_prob_grad_fn: The gradient of the target log probability function.
        step_size: The step size for the leapfrog integrator.
        num_steps: The number of steps for the leapfrog integrator.
    
    TODO(Issue #9): Add support for adaptive step size
    TODO(Issue #9): Implement MCMC diagnostics
    """
    
    def __init__(
        self,
        target_log_prob_fn: Callable[[np.ndarray], float],
        target_log_prob_grad_fn: Callable[[np.ndarray], np.ndarray],
        step_size: float = 0.1,
        num_steps: int = 10,
        name: str = "hamiltonian_mc"
    ) -> None:
        """
        Initialize the Hamiltonian Monte Carlo.
        
        Args:
            target_log_prob_fn: The target log probability function.
            target_log_prob_grad_fn: The gradient of the target log probability function.
            step_size: The step size for the leapfrog integrator.
            num_steps: The number of steps for the leapfrog integrator.
            name: The name of the MCMC method.
        """
        super().__init__(target_log_prob_fn, name)
        
        self.target_log_prob_grad_fn = target_log_prob_grad_fn
        self.step_size = step_size
        self.num_steps = num_steps
        
        self.metadata["step_size"] = step_size
        self.metadata["num_steps"] = num_steps
    
    def sample(
        self,
        initial_state: np.ndarray,
        num_samples: int,
        num_burnin: int = 0,
        thin: int = 1
    ) -> List[MCMCSample[np.ndarray]]:
        """
        Generate samples using Hamiltonian Monte Carlo.
        
        Args:
            initial_state: The initial state of the Markov chain.
            num_samples: The number of samples to generate.
            num_burnin: The number of burn-in samples to discard.
            thin: The thinning factor.
            
        Returns:
            The generated samples.
        """
        # Initialize the Markov chain
        current_state = initial_state.copy()
        current_log_prob = self.target_log_prob_fn(current_state)
        current_grad = self.target_log_prob_grad_fn(current_state)
        
        # Initialize samples
        samples = []
        
        # Run the Markov chain
        for i in range(num_burnin + num_samples * thin):
            # Sample momentum
            momentum = np.random.normal(0, 1, size=current_state.shape)
            
            # Compute Hamiltonian
            current_hamiltonian = -current_log_prob + 0.5 * np.sum(momentum ** 2)
            
            # Leapfrog integration
            proposed_state = current_state.copy()
            proposed_momentum = momentum.copy()
            
            # Half step for momentum
            proposed_momentum += 0.5 * self.step_size * current_grad
            
            # Full steps for position and momentum
            for _ in range(self.num_steps):
                # Full step for position
                proposed_state += self.step_size * proposed_momentum
                
                # Compute gradient at the new position
                proposed_grad = self.target_log_prob_grad_fn(proposed_state)
                
                # Full step for momentum, except at the end
                if _ < self.num_steps - 1:
                    proposed_momentum += self.step_size * proposed_grad
            
            # Half step for momentum at the end
            proposed_momentum += 0.5 * self.step_size * proposed_grad
            
            # Negate momentum for reversibility
            proposed_momentum = -proposed_momentum
            
            # Compute proposed Hamiltonian
            proposed_log_prob = self.target_log_prob_fn(proposed_state)
            proposed_hamiltonian = -proposed_log_prob + 0.5 * np.sum(proposed_momentum ** 2)
            
            # Compute the acceptance probability
            log_accept_prob = current_hamiltonian - proposed_hamiltonian
            
            # Accept or reject the proposal
            accepted = False
            if math.log(random.random()) < log_accept_prob:
                current_state = proposed_state
                current_log_prob = proposed_log_prob
                current_grad = self.target_log_prob_grad_fn(current_state)
                accepted = True
            
            # Store the sample
            if i >= num_burnin and (i - num_burnin) % thin == 0:
                sample = MCMCSample(current_state.copy(), current_log_prob)
                sample.set_metadata("accepted", accepted)
                samples.append(sample)
        
        # Store the samples
        self.samples = samples
        
        return samples
